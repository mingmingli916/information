:PROPERTIES:
:ID:       3E3773AD-6B20-4D3B-987D-1F7EF9CC8230
:END:
#+title: probability


Probability theory is a mathematical framework for representing uncertain statements.
Information theory enables us to quantify the amount of uncertain in a probability distribution.

* DONE random variables
A *random variables* is a variable that can take on different values randomly.
A random variable is just a description of the states that are possible; it must be coupled with a probability distribution that specifies how likely each of these states are.

* DONE probability distribution
A *probability distribution* is a description of how likely a random variable or set of random variables is to take on each of its possible states.

**** discrete variables and probability mass functions
*probability mass function* (PMF) over discrete variables.

Use ~ notation to specify which distribution it follows like $x \sim P(x)$.

*joint probability distribution* : a probability distribution over many variables.


To be a PMF on a random variable x, a function P must satisfy:
- the domain of P must be the set of all possible states of x
- $\forall x \in \mathrm{x}, 0 \le P(x) \le 1$
- $\sum_{x\in \mathrm{x}}P(x) = 1$


*uniform distribution* :
a discrete random variable x with $k$ different states
\begin{equation}
P(\mathrm{x}=x_i) = \frac{1}{k}
\end{equation}

**** continous variables and probability density functions
*probability density functions* (PDF) over continous variables.

To be a PDF, a function p must satisfy:
- the domain of $p$ must be the set of all possible states of x
- $\forall x \in \mathrm{x}, p(x) \ge 0$
- $\int p(x)dx = 1$

A probability density function $p(x)$ does not give the probability of a specific state directly; instead the probability of landing inside an infinitesimal region with volumn $\delta x$ is given by $p(x)\delta x$.


The ";" notation means "parameterized by" in $u(x;a,b)$.

* DONE marginal probability
The probability distribution over the subset is known as *marginal probability distribution*.
The name "marginal probability distribution" comes from the process of computing marginal probabilities on paper.

\begin{equation}
\forall x \in \mathrm{x}, P(\mathrm{x} = x) = \sum_y P(\mathrm{x}=x,\mathrm{y}=y)
\end{equation}

\begin{equation}
p(x)=\int p(x,y)dy
\end{equation}


* DONE conditional probability
We denote the conditional probability that $\mathrm{y}=y$ given $\mathrm{x}=x$ as $P(\mathrm{y}=y | \mathrm{x}=x)$.

\begin{equation}
P(\mathrm{y}=y | \mathrm{x}=x) = \frac{P(\mathrm{y}=y , \mathrm{x}=x)}{P(\mathrm{x}=x)}
\end{equation}

* DONE the chain rule of conditional probability
\begin{equation}
P(\mathrm{x}^{(1)},...,\mathrm{x}^{(n)}) = P(\mathrm{x}^{(1)})\prod_{i=1}^n P(\mathrm{x}^{(i)} | \mathrm{x}^{(1)},...,\mathrm{x}^{(i-1)})
\end{equation}

* DONE independence and conditional independence
x and y are *independent* if
\begin{equation}
\forall x \in \mathrm{x}, y \in \mathrm{y}, p(\mathrm{x}=x,\mathrm{y}=y) = p(\mathrm{x}=x)p(\mathrm{y}=y)
\end{equation}

*conditionally independent* :
\begin{equation}
\forall x \in \mathrm{x}, y \in \mathrm{y}, z \in \mathrm{z}, p(\mathrm{x}=x,\mathrm{y}=y | \mathrm{z}=z) = p(\mathrm{x}=x | \mathrm{z}=z)p(\mathrm{y}=y | \mathrm{z}=z)
\end{equation}

compact notation:
$\mathrm{x}\perp \mathrm{y}$ means that x and y are independent;
$\mathrm{x}\perp \mathrm{y} | \mathrm{z}$ means that x and y are conditionally independent given z.


* DONE expectation, variance and covariance
The *expectation*, or *expected value*, of some function $f(x)$ with respect to a probability distribution $P(x)$ is the average, or mean value, that $f$ takes on when x is drawn from P.

\begin{equation}
\mathbb{E}_{x\sim P} [f(x)] = \sum_x P(x)f(x)
\end{equation}
\begin{equation}
\mathbb{E}_{x\sim P} [f(x)] = \int p(x)f(x)dx
\end{equation}

expectation are linear:
\begin{equation}
\mathbb{E}_x [\alpha f(x) + \beta g(x)] = \alpha\mathbb{E}_x[f(x)] + \beta\mathbb{E}_x[g(x)]
\end{equation}

The *variance* gives a measure of how much the values of a function of a random variable x vary as we sample different values of $x$ from its probability distribution:
\begin{equation}
\mathrm{Var}(f(x)) = \mathbb{E}\left [(f(x) - \mathbb{E}[f(x)])^2 \right ]
\end{equation}

The *covariance* gives some sense of how much two values are linearly related to each other, as well as the scale of these variables:
\begin{equation}
\mathrm{Cov}(f(x),g(y)) = \mathbb{E}[(f(x)-\mathbb{E}[f(x)])(g(y)-\mathbb{E}[g(y)])]
\end{equation}

* DONE common probability distribution

**** Bernoulli distribution
The *Bernoulli distribution* is a distribution over a single binary random viarable.
\begin{equation}
P(\mathrm{x}=1) = \phi
\end{equation}
\begin{equation}
P(\mathrm{x}=0) = 1-\phi
\end{equation}
\begin{equation}
P(\mathrm{x}=x)=\phi^x(1-\phi)^{1-x}
\end{equation}
\begin{equation}
\mathbb{E}[\mathrm{x}]=\phi
\end{equation}
\begin{equation}
\mathrm{Var}=\phi(1-\phi)
\end{equation}

**** multinoulli distribution
The *multinoulli distribution*, or *categorical distribution* is a distribution over a single discrete variable with $k$ different states, where $k$ is finite.

**** Gaussian distribution (normal distribution)
\begin{equation}
\mathcal{N}(x;\mu,\sigma^2) = \sqrt{\frac{1}{2\pi\sigma^2}}\exp(-\frac{1}{2\sigma^2}(x-\mu)^2)
\end{equation}

where $\mathbb{E}[\mathrm{x}]=\mu$, $\mathrm{Var}(\mathrm{x})=\sigma^2$


In the absence of prior knowledge about what form a distribution over the real numbers should take, the normal distribution is a good default choice for two major reasons:
1. many distributions are truly close to being normal distributions.
2. it encodes the maximum amount of uncertainty over the real numbers.


The normal distribution generalizes to $\mathbb{R}^n$, known as *multivariable normal distribution*:
\begin{equation}
\mathcal{N}(x;\mu,\Sigma) = \sqrt{\frac{1}{(2\pi)^n\mathrm{det}(\Sigma)}}\exp\left(-\frac{1}{2}(x-\mu)^\top\Sigma^{-1}(x-\mu)\right)
\end{equation}

**** exponential and Laplace distribution
*exponential distribution*: (sharp point at $x=0$)
\begin{equation}
p(x;\lambda) = \lambda 1_{x\ge 0}\exp(-\lambda x)
\end{equation}

indicator function $1_{x\ge 0}$ assigns probability zero to all negative values of $x$.

*Laplace distribution* (sharp peak at point $\mu$)
\begin{equation}
\mathrm{Laplace}(x;u,\gamma) =\frac{1}{2\gamma}\exp\left(-\frac{|x-\mu|}{\gamma}\right)
\end{equation}

**** Dirac distribution and empirical distribution
*Dirac distribution*: (all the mass clusters around a single point)
\begin{equation}
p(x)=\delta(x-\mu)
\end{equation}


**** empirical distribution
\begin{equation}
\hat{p}(x) =\frac{1}{m}\sum_{i=1}^{m}\delta(x-x^{(i)})
\end{equation}

**** mixtures of distribution
A *mixtures distribution* is made up of several component distributions.

On each trial, the choice of which distribution should generate the sample is determined by sampling a compoent identity from a multinoulli distribution:
\begin{equation}
P(x) = \sum_iP(\mathrm{c}=i)P(\mathrm{x|c}=i)
\end{equation}

where $P(\mathrm{c})$ is the multinoulli distribution over component identities.

*latent variable* : a random variable that we cannot observe directly.

A *Gaussian mixture model* is a universal approximator of densities, in the sense that any smooth density can be approximated with any specific nonzero amount of error by A Gaussian mixture model with enough components.


* DONE useful properties of common functions

*logistic sigmoid*:
\begin{equation}
\sigma(x) = \frac{1}{1+e^{-x}}
\end{equation}

*softplus function*:
\begin{equation}
\zeta(x) = \log(1+e^x)
\end{equation}

The name of the softplus function comes from the fact that it is a smoothed, or "softened", version fo positive part function.

*positive part function*
\begin{equation}
x^+ = \max(0,x)
\end{equation}

useful properties:
\begin{equation}
\frac{d}{dx}\sigma(x) = \sigma(x)(1-\sigma(x))
\end{equation}
\begin{equation}
1-\sigma(x) = \sigma(-x)
\end{equation}
\begin{equation}
\log\sigma(x) = -\zeta(-x)
\end{equation}
\begin{equation}
\frac{d}{dx}\zeta(x) = \sigma(x)
\end{equation}
\begin{equation}
\forall x \in (0,1), \sigma^{-1}(x)=\log(\frac{x}{1-x})
\end{equation}
\begin{equation}
\forall x >0, \zeta^{-1}(x) = \log(e^x-1)
\end{equation}
\begin{equation}
\zeta(x)=\int_{-\infty}^x \sigma(y)dy
\end{equation}
\begin{equation}
\zeta(x)-\zeta(-x)=x
\end{equation}

* DONE Bayes' rule (conditional probability)
\begin{equation}
P(\mathrm{x|y}) = \frac{P(\mathrm{x})P(\mathrm{y|x})}{P(\mathrm{y})}
\end{equation}

* DONE information theory

The basic intuition behind information theory is that learning that an unlikely event has occurred is more informative than learning that a likely event has occurred.

quantify information in a way that formalizes this intuition:
- likely event should have low information content
- less likely events should have higher information content
- independent events should have additive information

*self-information* of an event $\mathrm{x}=x$ :
\begin{equation}
I(x)=-\log P(x)
\end{equation}


When x is continous, we use the same definition of information by analogy, but some of the properties from the discret case are lost.

*Shannon entropy* : quantify the amount of uncertainty in an entire probability distribution
\begin{equation}
H(\mathrm{x}) = \mathbb{E}_{x\sim P}[I(x)] = -\mathbb{E}_{x\sim P}[\log P(x)]
\end{equation}

When x is continous, the Shannon entropy is known as the *differential entropy*.


*Kullback-Leibler (KL) divergence*:
\begin{equation}
D_{\mathrm{KL}}(P||Q) = \mathbb{E}_{x\sim P}\left[\log \frac{P(x)}{Q(x)}\right] = \mathbb{E}_{x\sim P}[\log P(x) - \log Q(x)]
\end{equation}

*cross-entropy*
\begin{equation}
H(P,Q) = H(P)+D_{\mathrm{KL}}(P||Q) \Rightarrow H(P,Q) = -\mathbb{E}_{x\sim P}\log Q(x)
\end{equation}

* DONE structured probabilistic models
Machine learning algorithms often involve probability distributions over a very large number of random variables. Often, these probability distributions involve direct interactions between relatively few variables.

Instead of using a single function to represent a probability distribution, we can split a probability distribution into many factors that we multiply together.

These factorizations can greatly reduce the number of parameters needed to describe the distribution.

When we represent the factorization of a probability distribution with a graph, we call it a *structured probabilistic model* or *graphical model*.

Each node in the graph corresponds to a random variable, and an edge connecting two random variables means that the probability distribution is able to represent direct interactions between those two random variables.

*Directed models* represent factorizations into conditional probability distribution.
*Undirected models* represent factorizations into a set of functions.

[[file:pics/dl-directed.png]]

[[file:pics/dl-undirected.png]]

